{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb1e9ce3",
   "metadata": {},
   "source": [
    "# Let's give gymsnake a brain\n",
    "\n",
    "<img src=\"smartsnake.jpg\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "Neuroevolution worked very well for Cartpole. Let's therefore also apply it to gymsnake. Why gymsnake is a harder problem to tackle than Cartpole?\n",
    "\n",
    "Start with 'Neuroevolution for Gymnasium Cartpole' as a basis and transform it in such a way that it can be used for gymsnake. To do this, the following code changes need to be performed:\n",
    "* Load the gymsnake environment instead of the Cartpole environment\n",
    "* Use a snake grid of 4x4, otherwise learning takes a lot of time. On the other hand, with a too small grid, the luck factor becomes important, which impedes learning\n",
    "* Adapt the number of input neurons of the NN to the size of the observation of the gymsnake environment\n",
    "* Adapt the number of output neurons of the NN to the number of actions of the gymsnake environment\n",
    "* Cart pole episodes can be very long, easily 100000 steps. Gymsnake episodes typically do not exceed 400 steps. Adapt the `max_episode_length` to 400. Otherwise, when the snake is in an endless loop, we're waiting for nothing, as the snake is not learning\n",
    "* The `feed_forward()` method expects a 1D observation space, whereas as the observation space of gymsnake is 2D. Therefore, `flatten()` the observation space from 2D to 1D when passing the observation to the `step()` method: \n",
    "\n",
    "  `observation, reward, terminated, truncated, _ = env.step(self.feed_forward(np.array(observation).flatten()))`\n",
    "\n",
    "* Now the hard part, the hyperparameter values. These should be determined by means of trial & error. To save you time, the following hyperparameter values should show learning behavior; several tries might be needed:\n",
    "  * an NN with two hidden layers of each 64 neurons (Cartpole had only one hidden layer)\n",
    "  * population_size=1000\n",
    "  * generations=200\n",
    "  * n_episodes=1 (food is in same square at start, so no need to play multiple episodes)\n",
    "  * mutation_variance=0.2\n",
    "  \n",
    "You might need to run the program several times, because sometimes, the snake does not manage to find the food and therefore does not learn at all (the well-known bootstrapping problem). In these cases, the program finishes in 10 seconds. When learning occurs, the program takes about 5-10 minutes to finish on a reasonably fast laptop, using the hyperparameter values mentioned above.\n",
    "\n",
    "Once you've observed learning behavior (e.g. `Generation: 155 | Highest Reward: 8.0 | Average Reward: 0.4`) with the settings above, you can start to experiment to improve the performance. Two options are obvious candidates for experimentation:\n",
    "* Play with the hyperparameters\n",
    "* Currently the genetic algorithm only uses mutation to evolve. As form of elitism, only the best network is saved. No crossover is done. Play with the various ways of evolution and determine the effect on learning behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a6752b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gym register called for snake-v1!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from time import time\n",
    "import pickle\n",
    "import gymsnake\n",
    "\n",
    "def relu(x):\n",
    "    '''\n",
    "    activation function\n",
    "    '''\n",
    "    return np.where(x > 0, x, 0)\n",
    "\n",
    "def softmax(x):\n",
    "    '''\n",
    "    convert the output to probabilities by using softmax\n",
    "    '''\n",
    "    x = np.exp(x - np.max(x))\n",
    "    x[x == 0] = 1e-15  # to avoid division by 0\n",
    "    return np.array(x / x.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45d7f51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "    '''\n",
    "    neural network class that interacts with an Gymnasium environment\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, n_units=None, copy_network=None, var=0.02):\n",
    "        if copy_network is None:  # create new NN\n",
    "            self.n_units = n_units\n",
    "            weights = []\n",
    "            biases = []\n",
    "            # initialize weights and biases\n",
    "            for i in range(len(n_units)-1):\n",
    "                weights.append(np.random.normal(loc=0, scale=1, size=(n_units[i], n_units[i+1])))\n",
    "                biases.append(np.zeros(n_units[i+1]))\n",
    "            # put weights and biases in a dictionary\n",
    "            self.params = {'weights': weights,'biases': biases}\n",
    "        else:  # copy the NN\n",
    "            self.n_units = copy_network.n_units\n",
    "            weights = []\n",
    "            biases = []\n",
    "            for layer_weights in copy_network.params['weights']:\n",
    "                weights.append(layer_weights)\n",
    "            for layer_biases in copy_network.params['biases']:\n",
    "                biases.append(layer_biases)\n",
    "            self.params = {'weights': weights, 'biases': biases}\n",
    "            # perform mutation of weights and biases\n",
    "            self.params['weights'] = [x+np.random.normal(loc=0, scale=var, size=x.shape) for x in self.params['weights']]\n",
    "            self.params['biases'] = [x+np.random.normal(loc=0, scale=var, size=x.shape) for x in self.params['biases']]\n",
    "            \n",
    "    def feed_forward(self, X):\n",
    "        weights = self.params['weights']\n",
    "        biases = self.params['biases']\n",
    "        # first propagate inputs\n",
    "        a = relu((X@weights[0]) + biases[0])\n",
    "        # then propagate through every other layer\n",
    "        for layer in range(1, len(weights)):\n",
    "            a = relu((a@weights[layer]) + biases[layer])\n",
    "        probs = softmax(a)\n",
    "        return np.argmax(probs)\n",
    "        \n",
    "    def evaluate(self, n_episodes, max_episode_length, render_env):\n",
    "        '''\n",
    "        Evaluates the performance of the NN by playing plays `n_episodes` of the Cartpole game. \n",
    "        Actions are predicted by the NN. \n",
    "        Evaluate() returns the mean reward of the `n_episodes` games to obtain a reliable evaluation.\n",
    "        \n",
    "        max_episode_length: limits the max length of an episode to max_episode_length steps\n",
    "        render_env: boolean to turn on/off rendering of the environment\n",
    "        '''\n",
    "        env = gym.make('snake-v1', grid_size =(4, 4), render_mode=\"human\")\n",
    "        env._max_episode_steps=1e20  # do not use max episode length in Gymnasium TimeLimit wrapper\n",
    "            \n",
    "        rewards = []\n",
    "        for _ in range(n_episodes):\n",
    "            observation, info = env.reset()\n",
    "            episode_reward = 0\n",
    "            for _ in range(max_episode_length):\n",
    "                if render_env:\n",
    "                    env.render()\n",
    "                observation, reward, terminated, truncated, _ = env.step(self.feed_forward(np.array(observation).flatten()))\n",
    "                assert not truncated, 'episode truncated by Gymnasium' \n",
    "                done = terminated or truncated\n",
    "                episode_reward += reward\n",
    "                if done:\n",
    "                    rewards.append(episode_reward)\n",
    "                    break\n",
    "        env.close()\n",
    "\n",
    "        if len(rewards) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return np.array(rewards).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa66732f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justin\\MachineLearningPlayground\\ML4\\Challenge\\gymsnake1.0\\src\\gymsnake\\envs\\snake_env.py:201: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  self.fig.show()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try a random network\n",
    "random_network = NeuralNet(n_units=(16, 64, 64, 4))\n",
    "random_network.evaluate(n_episodes=1, max_episode_length=400, render_env=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ce01de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticAlg():\n",
    "    '''\n",
    "    handles the population of NNs    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, architecture, population_size, generations, mutation_variance, n_episodes, max_episode_length, \n",
    "                 render_env, verbose, print_every):\n",
    "        # create list of NNs\n",
    "        self.networks = [NeuralNet(architecture) for _ in range(population_size)]\n",
    "        self.best_network = NeuralNet(architecture)\n",
    "        self.population_size = population_size\n",
    "        self.generations = generations\n",
    "        self.mutation_variance = mutation_variance\n",
    "        self.fitness = []\n",
    "        self.n_episodes = n_episodes\n",
    "        self.max_episode_length = max_episode_length\n",
    "        self.render_env = render_env\n",
    "        self.verbose = verbose\n",
    "        self.print_every = print_every\n",
    "        \n",
    "    def fit(self):\n",
    "        '''\n",
    "        For every generation the following steps are performed:\n",
    "        - the performance of every member of the population is evaluated\n",
    "        - the best network is selected and its score is saved\n",
    "        - children are created that are mutations of the best network\n",
    "        - the best network survives into the next generation and children are added to the new generation\n",
    "        '''\n",
    "        for i in range(self.generations):\n",
    "            rewards = np.array([x.evaluate(self.n_episodes, self.max_episode_length, self.render_env) \n",
    "                                for x in self.networks])\n",
    "            # select the best NN\n",
    "            best_network = np.argmax(rewards)\n",
    "            # track best score per generation\n",
    "            self.fitness.append(np.max(rewards))\n",
    "            # create child NNs that are mutations of the best NN\n",
    "            new_networks = [NeuralNet(copy_network=self.networks[best_network], var=self.mutation_variance) \n",
    "                            for _ in range(self.population_size-1)]\n",
    "            # only the best NN survives + add the children\n",
    "            self.networks = [self.networks[best_network]] + new_networks\n",
    "            if self.verbose is True and (i % self.print_every == 0 or i == 0):\n",
    "                print(f'Generation: {i+1} | Highest Reward: {rewards.max().round(1)} | Average Reward: '\n",
    "                      f'{rewards.mean().round(1)}')\n",
    "        # save the best network for playing\n",
    "        self.best_network = self.networks[best_network]\n",
    "        with open('best_NN.pkl', 'wb') as f:\n",
    "            pickle.dump(self.best_network, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea38459f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation: 1 | Highest Reward: 0.0 | Average Reward: -1.0\n",
      "Generation: 2 | Highest Reward: 1.0 | Average Reward: -0.5\n",
      "Generation: 3 | Highest Reward: 1.0 | Average Reward: -0.1\n",
      "Generation: 4 | Highest Reward: 1.0 | Average Reward: -0.2\n",
      "Generation: 5 | Highest Reward: 1.0 | Average Reward: -0.3\n",
      "Generation: 6 | Highest Reward: 1.0 | Average Reward: -0.4\n",
      "Generation: 7 | Highest Reward: 1.0 | Average Reward: -0.4\n",
      "Generation: 8 | Highest Reward: 1.0 | Average Reward: -0.5\n",
      "Generation: 9 | Highest Reward: 1.0 | Average Reward: -0.2\n",
      "Generation: 10 | Highest Reward: 1.0 | Average Reward: -0.5\n",
      "Generation: 11 | Highest Reward: 1.0 | Average Reward: -0.3\n",
      "Generation: 12 | Highest Reward: 1.0 | Average Reward: -0.2\n",
      "Generation: 13 | Highest Reward: 1.0 | Average Reward: -0.3\n",
      "Generation: 14 | Highest Reward: 1.0 | Average Reward: -0.3\n",
      "Generation: 15 | Highest Reward: 1.0 | Average Reward: -0.7\n",
      "Generation: 16 | Highest Reward: 1.0 | Average Reward: -0.4\n",
      "Generation: 17 | Highest Reward: 1.0 | Average Reward: -0.3\n",
      "Generation: 18 | Highest Reward: 1.0 | Average Reward: -0.1\n",
      "Generation: 19 | Highest Reward: 1.0 | Average Reward: -0.3\n",
      "Generation: 20 | Highest Reward: 1.0 | Average Reward: -0.1\n",
      "Generation: 21 | Highest Reward: 1.0 | Average Reward: -0.0\n",
      "Generation: 22 | Highest Reward: 1.0 | Average Reward: 0.0\n",
      "Generation: 23 | Highest Reward: 1.0 | Average Reward: -0.2\n",
      "Generation: 24 | Highest Reward: 1.0 | Average Reward: -0.4\n",
      "Generation: 25 | Highest Reward: 2.0 | Average Reward: -0.3\n",
      "Generation: 26 | Highest Reward: 2.0 | Average Reward: -0.2\n",
      "Generation: 27 | Highest Reward: 2.0 | Average Reward: -0.0\n",
      "Generation: 28 | Highest Reward: 2.0 | Average Reward: 0.0\n",
      "Generation: 29 | Highest Reward: 2.0 | Average Reward: -0.0\n",
      "Generation: 30 | Highest Reward: 2.0 | Average Reward: 0.1\n",
      "Generation: 31 | Highest Reward: 2.0 | Average Reward: -0.2\n",
      "Generation: 32 | Highest Reward: 2.0 | Average Reward: -0.1\n",
      "Generation: 33 | Highest Reward: 2.0 | Average Reward: -0.2\n",
      "Generation: 34 | Highest Reward: 2.0 | Average Reward: -0.3\n",
      "Generation: 35 | Highest Reward: 2.0 | Average Reward: -0.1\n",
      "Generation: 36 | Highest Reward: 2.0 | Average Reward: -0.1\n",
      "Generation: 37 | Highest Reward: 2.0 | Average Reward: -0.3\n",
      "Generation: 38 | Highest Reward: 2.0 | Average Reward: -0.3\n",
      "Generation: 39 | Highest Reward: 2.0 | Average Reward: -0.4\n",
      "Generation: 40 | Highest Reward: 2.0 | Average Reward: -0.1\n",
      "Generation: 41 | Highest Reward: 2.0 | Average Reward: -0.1\n",
      "Generation: 42 | Highest Reward: 2.0 | Average Reward: -0.1\n",
      "Generation: 43 | Highest Reward: 2.0 | Average Reward: 0.1\n",
      "Generation: 44 | Highest Reward: 2.0 | Average Reward: 0.1\n",
      "Generation: 45 | Highest Reward: 2.0 | Average Reward: -0.1\n",
      "Generation: 46 | Highest Reward: 1.0 | Average Reward: -0.1\n",
      "Generation: 47 | Highest Reward: 2.0 | Average Reward: -0.2\n",
      "Generation: 48 | Highest Reward: 2.0 | Average Reward: 0.0\n",
      "Generation: 49 | Highest Reward: 2.0 | Average Reward: 0.1\n",
      "Generation: 50 | Highest Reward: 2.0 | Average Reward: 0.0\n",
      "Generation: 51 | Highest Reward: 2.0 | Average Reward: -0.5\n",
      "Generation: 52 | Highest Reward: 2.0 | Average Reward: -0.0\n",
      "Generation: 53 | Highest Reward: 2.0 | Average Reward: -0.3\n",
      "Generation: 54 | Highest Reward: 2.0 | Average Reward: 0.0\n",
      "Generation: 55 | Highest Reward: 2.0 | Average Reward: 0.2\n",
      "Generation: 56 | Highest Reward: 2.0 | Average Reward: 0.2\n",
      "Generation: 57 | Highest Reward: 2.0 | Average Reward: 0.1\n",
      "Generation: 58 | Highest Reward: 2.0 | Average Reward: 0.1\n",
      "Generation: 59 | Highest Reward: 2.0 | Average Reward: -0.1\n",
      "Generation: 60 | Highest Reward: 2.0 | Average Reward: -0.2\n",
      "Generation: 61 | Highest Reward: 2.0 | Average Reward: -0.0\n",
      "Generation: 62 | Highest Reward: 2.0 | Average Reward: 0.1\n",
      "Generation: 63 | Highest Reward: 2.0 | Average Reward: 0.1\n",
      "Generation: 64 | Highest Reward: 2.0 | Average Reward: -0.1\n",
      "Generation: 65 | Highest Reward: 2.0 | Average Reward: -0.0\n",
      "Generation: 66 | Highest Reward: 2.0 | Average Reward: -0.5\n",
      "Generation: 67 | Highest Reward: 2.0 | Average Reward: -0.4\n",
      "Generation: 68 | Highest Reward: 2.0 | Average Reward: -0.0\n",
      "Generation: 69 | Highest Reward: 2.0 | Average Reward: -0.0\n",
      "Generation: 70 | Highest Reward: 2.0 | Average Reward: -0.0\n",
      "Generation: 71 | Highest Reward: 2.0 | Average Reward: -0.1\n",
      "Generation: 72 | Highest Reward: 2.0 | Average Reward: -0.2\n",
      "Generation: 73 | Highest Reward: 2.0 | Average Reward: -0.1\n",
      "Generation: 74 | Highest Reward: 2.0 | Average Reward: 0.1\n",
      "Generation: 75 | Highest Reward: 2.0 | Average Reward: 0.1\n",
      "Generation: 76 | Highest Reward: 2.0 | Average Reward: 0.1\n",
      "Generation: 77 | Highest Reward: 2.0 | Average Reward: 0.1\n",
      "Generation: 78 | Highest Reward: 2.0 | Average Reward: 0.0\n",
      "Generation: 79 | Highest Reward: 2.0 | Average Reward: -0.5\n",
      "Generation: 80 | Highest Reward: 2.0 | Average Reward: -0.5\n",
      "Generation: 81 | Highest Reward: 2.0 | Average Reward: -0.5\n",
      "Generation: 82 | Highest Reward: 2.0 | Average Reward: -0.5\n",
      "Generation: 83 | Highest Reward: 2.0 | Average Reward: -0.7\n",
      "Generation: 84 | Highest Reward: 2.0 | Average Reward: -0.5\n",
      "Generation: 85 | Highest Reward: 2.0 | Average Reward: -0.2\n",
      "Generation: 86 | Highest Reward: 2.0 | Average Reward: -0.7\n",
      "Generation: 87 | Highest Reward: 2.0 | Average Reward: -0.5\n",
      "Generation: 88 | Highest Reward: 2.0 | Average Reward: -0.6\n",
      "Generation: 89 | Highest Reward: 2.0 | Average Reward: -0.4\n",
      "Generation: 90 | Highest Reward: 2.0 | Average Reward: -0.3\n",
      "Generation: 91 | Highest Reward: 2.0 | Average Reward: 0.0\n",
      "Generation: 92 | Highest Reward: 2.0 | Average Reward: 0.0\n",
      "Generation: 93 | Highest Reward: 2.0 | Average Reward: 0.0\n",
      "Generation: 94 | Highest Reward: 2.0 | Average Reward: -0.2\n",
      "Generation: 95 | Highest Reward: 2.0 | Average Reward: -0.2\n",
      "Generation: 96 | Highest Reward: 2.0 | Average Reward: -0.2\n",
      "Generation: 97 | Highest Reward: 2.0 | Average Reward: -0.3\n",
      "Generation: 98 | Highest Reward: 2.0 | Average Reward: -0.4\n",
      "Generation: 99 | Highest Reward: 2.0 | Average Reward: -0.3\n",
      "Generation: 100 | Highest Reward: 2.0 | Average Reward: -0.0\n",
      "Generation: 101 | Highest Reward: 2.0 | Average Reward: -0.4\n",
      "Generation: 102 | Highest Reward: 2.0 | Average Reward: -0.4\n",
      "Generation: 103 | Highest Reward: 2.0 | Average Reward: -0.1\n",
      "Generation: 104 | Highest Reward: 2.0 | Average Reward: -0.0\n",
      "Generation: 105 | Highest Reward: 2.0 | Average Reward: 0.1\n",
      "Generation: 106 | Highest Reward: 2.0 | Average Reward: 0.1\n",
      "Generation: 107 | Highest Reward: 2.0 | Average Reward: -0.2\n",
      "Generation: 108 | Highest Reward: 2.0 | Average Reward: -0.5\n",
      "Generation: 109 | Highest Reward: 2.0 | Average Reward: -0.4\n",
      "Generation: 110 | Highest Reward: 2.0 | Average Reward: -0.4\n",
      "Generation: 111 | Highest Reward: 2.0 | Average Reward: -0.2\n",
      "Generation: 112 | Highest Reward: 2.0 | Average Reward: -0.3\n",
      "Generation: 113 | Highest Reward: 2.0 | Average Reward: -0.2\n",
      "Generation: 114 | Highest Reward: 2.0 | Average Reward: -0.3\n",
      "Generation: 115 | Highest Reward: 2.0 | Average Reward: -0.3\n",
      "Generation: 116 | Highest Reward: 2.0 | Average Reward: -0.0\n",
      "Generation: 117 | Highest Reward: 2.0 | Average Reward: -0.3\n",
      "Generation: 118 | Highest Reward: 2.0 | Average Reward: -0.2\n",
      "Generation: 119 | Highest Reward: 1.0 | Average Reward: -0.5\n",
      "Generation: 120 | Highest Reward: 2.0 | Average Reward: -0.3\n",
      "Generation: 121 | Highest Reward: 2.0 | Average Reward: -0.2\n",
      "Generation: 122 | Highest Reward: 2.0 | Average Reward: -0.1\n",
      "Generation: 123 | Highest Reward: 2.0 | Average Reward: 0.0\n",
      "Generation: 124 | Highest Reward: 2.0 | Average Reward: -0.0\n",
      "Generation: 125 | Highest Reward: 2.0 | Average Reward: 0.0\n",
      "Generation: 126 | Highest Reward: 2.0 | Average Reward: 0.0\n",
      "Generation: 127 | Highest Reward: 2.0 | Average Reward: -0.2\n",
      "Generation: 128 | Highest Reward: 2.0 | Average Reward: -0.4\n",
      "Generation: 129 | Highest Reward: 1.0 | Average Reward: -0.1\n",
      "Generation: 130 | Highest Reward: 2.0 | Average Reward: -0.2\n",
      "Generation: 131 | Highest Reward: 2.0 | Average Reward: -0.1\n",
      "Generation: 132 | Highest Reward: 2.0 | Average Reward: -0.1\n",
      "Generation: 133 | Highest Reward: 2.0 | Average Reward: -0.1\n",
      "Generation: 134 | Highest Reward: 2.0 | Average Reward: 0.1\n",
      "Generation: 135 | Highest Reward: 2.0 | Average Reward: -0.4\n",
      "Generation: 136 | Highest Reward: 2.0 | Average Reward: -0.3\n",
      "Generation: 137 | Highest Reward: 2.0 | Average Reward: -0.1\n",
      "Generation: 138 | Highest Reward: 2.0 | Average Reward: -0.3\n",
      "Generation: 139 | Highest Reward: 2.0 | Average Reward: 0.0\n",
      "Generation: 140 | Highest Reward: 2.0 | Average Reward: 0.0\n",
      "Generation: 141 | Highest Reward: 2.0 | Average Reward: -0.1\n",
      "Generation: 142 | Highest Reward: 2.0 | Average Reward: 0.1\n",
      "Generation: 143 | Highest Reward: 2.0 | Average Reward: 0.0\n",
      "Generation: 144 | Highest Reward: 2.0 | Average Reward: -0.2\n",
      "Generation: 145 | Highest Reward: 2.0 | Average Reward: -0.3\n",
      "Generation: 146 | Highest Reward: 2.0 | Average Reward: 0.1\n",
      "Generation: 147 | Highest Reward: 2.0 | Average Reward: 0.1\n",
      "Generation: 148 | Highest Reward: 2.0 | Average Reward: -0.1\n",
      "Generation: 149 | Highest Reward: 2.0 | Average Reward: -0.2\n",
      "Generation: 150 | Highest Reward: 2.0 | Average Reward: -0.1\n",
      "Generation: 151 | Highest Reward: 2.0 | Average Reward: -0.4\n",
      "Generation: 152 | Highest Reward: 2.0 | Average Reward: -0.0\n",
      "Generation: 153 | Highest Reward: 2.0 | Average Reward: -0.1\n",
      "Generation: 154 | Highest Reward: 2.0 | Average Reward: -0.4\n",
      "Generation: 155 | Highest Reward: 2.0 | Average Reward: -0.4\n",
      "Generation: 156 | Highest Reward: 2.0 | Average Reward: -0.1\n",
      "Generation: 157 | Highest Reward: 1.0 | Average Reward: -0.4\n",
      "Generation: 158 | Highest Reward: 2.0 | Average Reward: -0.1\n",
      "Generation: 159 | Highest Reward: 2.0 | Average Reward: -0.2\n",
      "Generation: 160 | Highest Reward: 2.0 | Average Reward: -0.6\n",
      "Generation: 161 | Highest Reward: 2.0 | Average Reward: -0.5\n",
      "Generation: 162 | Highest Reward: 2.0 | Average Reward: -0.3\n",
      "Generation: 163 | Highest Reward: 2.0 | Average Reward: -0.2\n",
      "Generation: 164 | Highest Reward: 2.0 | Average Reward: 0.0\n",
      "Generation: 165 | Highest Reward: 2.0 | Average Reward: 0.0\n",
      "Generation: 166 | Highest Reward: 2.0 | Average Reward: -0.4\n",
      "Generation: 167 | Highest Reward: 2.0 | Average Reward: 0.0\n",
      "Generation: 168 | Highest Reward: 2.0 | Average Reward: -0.0\n",
      "Generation: 169 | Highest Reward: 2.0 | Average Reward: -0.3\n",
      "Generation: 170 | Highest Reward: 2.0 | Average Reward: -0.1\n",
      "Generation: 171 | Highest Reward: 2.0 | Average Reward: -0.4\n",
      "Generation: 172 | Highest Reward: 2.0 | Average Reward: 0.1\n",
      "Generation: 173 | Highest Reward: 2.0 | Average Reward: 0.0\n",
      "Generation: 174 | Highest Reward: 2.0 | Average Reward: 0.1\n",
      "Generation: 175 | Highest Reward: 2.0 | Average Reward: 0.1\n",
      "Generation: 176 | Highest Reward: 2.0 | Average Reward: -0.2\n",
      "Generation: 177 | Highest Reward: 2.0 | Average Reward: -0.1\n",
      "Generation: 178 | Highest Reward: 2.0 | Average Reward: -0.1\n",
      "Generation: 179 | Highest Reward: 2.0 | Average Reward: -0.3\n",
      "Generation: 180 | Highest Reward: 2.0 | Average Reward: -0.3\n",
      "Generation: 181 | Highest Reward: 2.0 | Average Reward: 0.0\n",
      "Generation: 182 | Highest Reward: 2.0 | Average Reward: -0.2\n",
      "Generation: 183 | Highest Reward: 2.0 | Average Reward: 0.1\n",
      "Generation: 184 | Highest Reward: 2.0 | Average Reward: -0.3\n",
      "Generation: 185 | Highest Reward: 2.0 | Average Reward: -0.3\n",
      "Generation: 186 | Highest Reward: 2.0 | Average Reward: -0.6\n",
      "Generation: 187 | Highest Reward: 2.0 | Average Reward: -0.4\n",
      "Generation: 188 | Highest Reward: 2.0 | Average Reward: -0.5\n",
      "Generation: 189 | Highest Reward: 2.0 | Average Reward: -0.2\n",
      "Generation: 190 | Highest Reward: 2.0 | Average Reward: -0.5\n",
      "Generation: 191 | Highest Reward: 2.0 | Average Reward: -0.5\n",
      "Generation: 192 | Highest Reward: 2.0 | Average Reward: -0.3\n",
      "Generation: 193 | Highest Reward: 2.0 | Average Reward: -0.5\n",
      "Generation: 194 | Highest Reward: 2.0 | Average Reward: -0.5\n",
      "Generation: 195 | Highest Reward: 2.0 | Average Reward: -0.1\n",
      "Generation: 196 | Highest Reward: 2.0 | Average Reward: -0.4\n",
      "Generation: 197 | Highest Reward: 2.0 | Average Reward: 0.0\n",
      "Generation: 198 | Highest Reward: 2.0 | Average Reward: 0.0\n",
      "Generation: 199 | Highest Reward: 2.0 | Average Reward: -0.0\n",
      "Generation: 200 | Highest Reward: 2.0 | Average Reward: -0.1\n",
      "Finished in 330.959 seconds\n"
     ]
    }
   ],
   "source": [
    "# train a population of NNs\n",
    "start_time = time()\n",
    "# hyperparameter values determined by means of trial and error!!\n",
    "genetic_population = GeneticAlg(architecture=(16, 64, 64, 4),\n",
    "                         population_size=1000, \n",
    "                         generations=200,\n",
    "                         mutation_variance=0.2,\n",
    "                         n_episodes=1, \n",
    "                         max_episode_length=10000,\n",
    "                         render_env=False,\n",
    "                         verbose=True,\n",
    "                         print_every=1)\n",
    "genetic_population.fit()\n",
    "print(f'Finished in {round(time() - start_time, 3)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3ab0f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best network from disk\n",
    "with open('best_NN.pkl', 'rb') as f:\n",
    "    genetic_population.best_network = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e34c275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# play an episode using the best network\n",
    "genetic_population.best_network.evaluate(n_episodes=1, max_episode_length=int(1e10), render_env=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8912237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
