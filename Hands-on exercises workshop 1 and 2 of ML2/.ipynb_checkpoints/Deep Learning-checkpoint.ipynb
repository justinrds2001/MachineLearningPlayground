{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "## Shallow and Deep Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# create datset\n",
    "X, y = make_moons(n_samples=1000, noise=0.1, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# data exploration\n",
    "print(X.shape)\n",
    "plt.plot(X[y==0, 0], X[y==0, 1], 'ob', alpha=0.5)\n",
    "plt.plot(X[y==1, 0], X[y==1, 1], 'xr', alpha=0.5)\n",
    "plt.legend(['0', '1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_shape=(2,), activation='sigmoid'))\n",
    "model.compile(Adam(learning_rate=0.05), 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# visualize model architecture\n",
    "plot_model(model, to_file='shallow_model_plot.png', show_shapes=True, show_layer_names=True, \n",
    "           show_layer_activations=True, rankdir=\"LR\", dpi=256)\n",
    "\n",
    "# train model\n",
    "model.fit(X_train, y_train, epochs=200, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "print(\"The Accuracy score on the train set is:\\t{:0.3f}\".format(results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model, X, y):\n",
    "    amin, bmin = X.min(axis=0) - 0.1\n",
    "    amax, bmax = X.max(axis=0) + 0.1\n",
    "    hticks = np.linspace(amin, amax, 101)\n",
    "    vticks = np.linspace(bmin, bmax, 101)\n",
    "    \n",
    "    aa, bb = np.meshgrid(hticks, vticks)\n",
    "    ab = np.c_[aa.ravel(), bb.ravel()]\n",
    "    \n",
    "    c = model.predict(ab)\n",
    "    cc = c.reshape(aa.shape)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    CS = plt.contourf(aa, bb, cc, cmap='bwr', alpha=0.2)\n",
    "    plt.clabel(CS, inline=True, fontsize=12)\n",
    "    plt.plot(X[y==0, 0], X[y==0, 1], 'ob', alpha=0.5)\n",
    "    plt.plot(X[y==1, 0], X[y==1, 1], 'xr', alpha=0.5)\n",
    "    plt.title(\"Decision boundary of model (default threshold is usually 0.5)\")\n",
    "    \n",
    "plot_decision_boundary(model, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_shape=(2,), activation='tanh'))\n",
    "model.add(Dense(2, activation='tanh'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(Adam(learning_rate=0.05), 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# visualize model architecture\n",
    "plot_model(model, to_file='deep_model_plot.png', show_shapes=True, show_layer_names=True, \n",
    "           show_layer_activations=True, rankdir=\"LR\", dpi=256)\n",
    "\n",
    "# train model\n",
    "model.fit(X_train, y_train, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred = y_train_pred > threshold\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_pred = y_test_pred > threshold\n",
    "\n",
    "print(\"The Accuracy score on the train set is:\\t{:0.3f}\".format(accuracy_score(y_train, y_train_pred)))\n",
    "print(\"The Accuracy score on the test set is:\\t{:0.3f}\".format(accuracy_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundary(model, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class classification with the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "df = pd.read_csv('iris.csv')\n",
    "\n",
    "# data exploration\n",
    "sns.pairplot(df, hue=\"species\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "X = df.drop('species', axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easier alternative for transforming strings to numerical labels is to use sklearn.preprocessing.LabelEncoder()\n",
    "target_names = df['species'].unique()\n",
    "print(target_names)\n",
    "\n",
    "target_dict = {n:i for i, n in enumerate(target_names)}\n",
    "print(target_dict)\n",
    "y = df['species'].map(target_dict) \n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easier alternative for one-hot encoding is to use pandas.get_dummies()\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "y_cat = to_categorical(y)\n",
    "y_cat[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y_cat,\n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(3, input_shape=(4,), activation='softmax'))\n",
    "model.compile(Adam(learning_rate=0.1), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# visualize model architecture\n",
    "plot_model(model, to_file='iris_model_plot.png', show_shapes=True, show_layer_names=True, \n",
    "           show_layer_activations=True, rankdir=\"LR\", dpi=256)\n",
    "\n",
    "# train model\n",
    "model.fit(X_train, y_train, epochs=20, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "y_pred = model.predict(X_test)\n",
    "print(f'\\n\\n{y_pred[:5]}')\n",
    "\n",
    "y_test_class = np.argmax(y_test, axis=1)\n",
    "y_pred_class = np.argmax(y_pred, axis=1)\n",
    "print(f'\\n\\n{y_pred_class[:5]}')\n",
    "\n",
    "print('\\n\\nclassification report:')\n",
    "print(classification_report(y_test_class, y_pred_class))\n",
    "\n",
    "print('\\n\\nconfusion matrix:')\n",
    "confusion_matrix(y_test_class, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions about Iris classification\n",
    "\n",
    "* Why do we perform one-hot encoding of the label y during the feature engineering step?\n",
    "* Why do we use np.argmax() during the evaluation step?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
